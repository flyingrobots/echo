// SPDX-License-Identifier: Apache-2.0
// © James Ross Ω FLYING•ROBOTS <https://github.com/flyingrobots>
//! CLI that reads TTD IR JSON from stdin and emits Rust artifacts for Echo TTD.

use anyhow::Result;
use clap::Parser;
use proc_macro2::TokenStream;
use quote::{format_ident, quote};
use std::io::{self, Read};

mod ir;
use ir::TtdIR;

/// Create an identifier safely, falling back to a raw identifier for Rust keywords.
fn safe_ident(name: &str) -> proc_macro2::Ident {
    syn::parse_str::<proc_macro2::Ident>(name)
        .unwrap_or_else(|_| proc_macro2::Ident::new_raw(name, proc_macro2::Span::call_site()))
}

#[derive(Parser)]
#[command(
    author,
    version,
    about = "Generates Echo TTD Rust artifacts from TTD IR"
)]
struct Args {
    /// Optional output path (defaults to stdout)
    #[arg(short, long)]
    out: Option<std::path::PathBuf>,
}

fn main() -> Result<()> {
    let args = Args::parse();

    let mut buffer = String::new();
    io::stdin().read_to_string(&mut buffer)?;

    let ir: TtdIR = serde_json::from_str(&buffer)?;
    validate_version(&ir)?;
    let code = generate_rust(&ir)?;

    if let Some(path) = args.out {
        std::fs::write(path, code)?;
    } else {
        println!("{code}");
    }

    Ok(())
}

fn validate_version(ir: &TtdIR) -> Result<()> {
    const SUPPORTED: &str = "ttd-ir/v1";
    match ir.ir_version.as_deref() {
        Some(SUPPORTED) => Ok(()),
        Some(other) => anyhow::bail!(
            "Unsupported ir_version '{}'; expected '{}'. Please regenerate IR with a compatible Wesley TTD compiler.",
            other,
            SUPPORTED
        ),
        None => anyhow::bail!(
            "Missing ir_version; expected '{}'. Regenerate IR with Wesley TTD compiler.",
            SUPPORTED
        ),
    }
}

fn generate_rust(ir: &TtdIR) -> Result<String> {
    let mut tokens = quote! {
        // Generated by echo-ttd-gen from TTD IR. Do not edit.
        #![allow(
            dead_code,
            clippy::derivable_impls,
            non_snake_case,
            non_camel_case_types,
            missing_docs
        )]
        use serde::{Serialize, Deserialize};
    };

    // Schema metadata
    let schema_hash = ir.schema_sha256.as_deref().unwrap_or("");
    let generated_at = ir.generated_at.as_deref().unwrap_or("");

    tokens.extend(quote! {
        /// SHA256 hash of the source TTD schema.
        pub const SCHEMA_SHA256: &str = #schema_hash;
        /// Timestamp when this code was generated.
        pub const GENERATED_AT: &str = #generated_at;
    });

    // Generate enums first (types may reference them)
    tokens.extend(generate_enums(ir));

    // Generate types
    tokens.extend(generate_types(ir));

    // Generate channels
    tokens.extend(generate_channels(ir));

    // Generate ops
    tokens.extend(generate_ops(ir));

    // Generate rules
    tokens.extend(generate_rules(ir));

    // Generate footprints
    tokens.extend(generate_footprints(ir));

    // Generate registry
    tokens.extend(generate_registry(ir));

    // Generate invariants
    tokens.extend(generate_invariants(ir));

    // Generate emissions
    tokens.extend(generate_emissions(ir));

    let syntax_tree = syn::parse2(tokens)?;
    Ok(prettyplease::unparse(&syntax_tree))
}

fn generate_enums(ir: &TtdIR) -> TokenStream {
    if ir.enums.is_empty() {
        return quote! {};
    }

    let mut tokens = quote! {
        // ─── Enums ───────────────────────────────────────────────────────────────
    };

    for en in &ir.enums {
        let name = safe_ident(&en.name);
        let variants: Vec<_> = en.values.iter().map(|v| safe_ident(v)).collect();
        let first_variant = variants.first().cloned();

        tokens.extend(quote! {
            #[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
            pub enum #name {
                #(#variants),*
            }
        });

        // Only generate Default if there's at least one variant
        if let Some(first) = first_variant {
            tokens.extend(quote! {
                impl Default for #name {
                    fn default() -> Self {
                        Self::#first
                    }
                }
            });
        }
    }

    tokens
}

fn generate_types(ir: &TtdIR) -> TokenStream {
    if ir.types.is_empty() {
        return quote! {};
    }

    let mut tokens = quote! {
        // ─── Types ───────────────────────────────────────────────────────────────
    };

    for ty in &ir.types {
        let name = safe_ident(&ty.name);
        let fields: Vec<_> = ty
            .fields
            .iter()
            .map(|f| {
                let field_name = safe_ident(&f.name);
                let base_ty = map_type(&f.type_name);

                let full_ty: TokenStream = if f.list {
                    quote! { Vec<#base_ty> }
                } else {
                    quote! { #base_ty }
                };

                if f.required {
                    quote! { pub #field_name: #full_ty }
                } else {
                    quote! { pub #field_name: Option<#full_ty> }
                }
            })
            .collect();

        tokens.extend(quote! {
            #[derive(Debug, Clone, Serialize, Deserialize)]
            pub struct #name {
                #(#fields),*
            }
        });
    }

    tokens
}

fn generate_channels(ir: &TtdIR) -> TokenStream {
    if ir.channels.is_empty() {
        return quote! {};
    }

    let mut tokens = quote! {
        // ─── Channels ────────────────────────────────────────────────────────────

        /// Channel metadata.
        #[derive(Debug, Clone)]
        pub struct ChannelInfo {
            pub name: &'static str,
            pub version: u16,
            pub event_types: &'static [&'static str],
            pub ordered: bool,
            pub persistent: bool,
        }
    };

    let mut channel_consts = Vec::new();
    let mut channel_entries = Vec::new();

    for ch in &ir.channels {
        let name = &ch.name;
        let const_name = format_ident!("CHANNEL_{}", sanitize_ident(name).to_uppercase());
        let version = ch.version.unwrap_or(1);
        let event_types: Vec<_> = ch.event_types.iter().map(|e| e.as_str()).collect();
        let ordered = ch.ordered;
        let persistent = ch.persistent;

        channel_consts.push(quote! {
            pub const #const_name: &str = #name;
        });

        channel_entries.push(quote! {
            ChannelInfo {
                name: #name,
                version: #version,
                event_types: &[#(#event_types),*],
                ordered: #ordered,
                persistent: #persistent,
            }
        });
    }

    tokens.extend(quote! {
        #(#channel_consts)*

        pub const CHANNELS: &[ChannelInfo] = &[
            #(#channel_entries),*
        ];

        pub fn channel_by_name(name: &str) -> Option<&'static ChannelInfo> {
            CHANNELS.iter().find(|c| c.name == name)
        }
    });

    tokens
}

fn generate_ops(ir: &TtdIR) -> TokenStream {
    if ir.ops.is_empty() {
        return quote! {};
    }

    let mut tokens = quote! {
        // ─── Ops ─────────────────────────────────────────────────────────────────

        /// Op metadata.
        #[derive(Debug, Clone)]
        pub struct OpInfo {
            pub name: &'static str,
            pub op_id: u32,
            pub result_type: &'static str,
            pub idempotent: bool,
            pub readonly: bool,
            pub arg_count: usize,
        }

        /// Argument metadata for ops.
        #[derive(Debug, Clone)]
        pub struct ArgInfo {
            pub name: &'static str,
            pub type_name: &'static str,
            pub required: bool,
            pub list: bool,
        }
    };

    let mut op_consts = Vec::new();
    let mut op_entries = Vec::new();
    let mut arg_structs = Vec::new();
    let mut arg_info_arrays = Vec::new();

    for op in &ir.ops {
        let name = &op.name;
        let const_name = format_ident!("OP_{}", name.to_uppercase());
        let op_id = op.op_id;
        let result_type = &op.result_type;
        let idempotent = op.idempotent;
        let readonly = op.readonly;
        let arg_count = op.args.len();

        op_consts.push(quote! {
            pub const #const_name: u32 = #op_id;
        });

        op_entries.push(quote! {
            OpInfo {
                name: #name,
                op_id: #op_id,
                result_type: #result_type,
                idempotent: #idempotent,
                readonly: #readonly,
                arg_count: #arg_count,
            }
        });

        // Generate Args struct if op has arguments
        if !op.args.is_empty() {
            let args_struct_name = format_ident!("{}Args", pascal_case(name));
            let args_info_name = format_ident!("{}_ARGS", name.to_uppercase());

            let fields: Vec<_> = op
                .args
                .iter()
                .map(|arg| {
                    let field_name = safe_ident(&arg.name);
                    let base_ty = map_type(&arg.type_name);

                    let full_ty: TokenStream = if arg.list {
                        quote! { Vec<#base_ty> }
                    } else {
                        quote! { #base_ty }
                    };

                    if arg.required {
                        quote! { pub #field_name: #full_ty }
                    } else {
                        quote! { pub #field_name: Option<#full_ty> }
                    }
                })
                .collect();

            let doc_comment = format!("Arguments for the `{}` operation.", name);
            arg_structs.push(quote! {
                #[doc = #doc_comment]
                #[derive(Debug, Clone, Serialize, Deserialize)]
                pub struct #args_struct_name {
                    #(#fields),*
                }
            });

            // Generate ArgInfo array for this op
            let arg_infos: Vec<_> = op
                .args
                .iter()
                .map(|arg| {
                    let arg_name = &arg.name;
                    let type_name = &arg.type_name;
                    let required = arg.required;
                    let list = arg.list;
                    quote! {
                        ArgInfo {
                            name: #arg_name,
                            type_name: #type_name,
                            required: #required,
                            list: #list,
                        }
                    }
                })
                .collect();

            arg_info_arrays.push(quote! {
                pub const #args_info_name: &[ArgInfo] = &[
                    #(#arg_infos),*
                ];
            });
        }
    }

    tokens.extend(quote! {
        #(#op_consts)*

        // Op argument structs
        #(#arg_structs)*

        // Op argument metadata
        #(#arg_info_arrays)*

        pub const OPS: &[OpInfo] = &[
            #(#op_entries),*
        ];

        pub fn op_by_id(op_id: u32) -> Option<&'static OpInfo> {
            OPS.iter().find(|o| o.op_id == op_id)
        }

        pub fn op_by_name(name: &str) -> Option<&'static OpInfo> {
            OPS.iter().find(|o| o.name == name)
        }
    });

    tokens
}

/// Sanitize a name for use as a Rust identifier (replace dots, dashes with underscores).
fn sanitize_ident(s: &str) -> String {
    s.replace(['.', '-'], "_")
}

/// Convert a string to PascalCase.
fn pascal_case(s: &str) -> String {
    let mut result = String::new();
    let mut capitalize_next = true;
    for c in s.chars() {
        if c == '_' || c == '-' {
            capitalize_next = true;
        } else if capitalize_next {
            result.push(c.to_ascii_uppercase());
            capitalize_next = false;
        } else {
            result.push(c);
        }
    }
    result
}

fn generate_rules(ir: &TtdIR) -> TokenStream {
    if ir.rules.is_empty() {
        return quote! {};
    }

    let mut tokens = quote! {
        // ─── Rules (State Machine Transitions) ───────────────────────────────────

        /// Rule metadata (state machine transition).
        #[derive(Debug, Clone)]
        pub struct RuleInfo {
            pub name: &'static str,
            pub from_states: &'static [&'static str],
            pub to_state: &'static str,
            pub op_name: &'static str,
            pub guard: Option<&'static str>,
        }
    };

    let mut rule_entries = Vec::new();

    for rule in &ir.rules {
        let name = &rule.name;
        let from_states: Vec<_> = rule.from.iter().map(|s| s.as_str()).collect();
        let to_state = &rule.to;
        let op_name = &rule.op_name;
        let guard = rule.guard.as_deref();

        let guard_token = match guard {
            Some(g) => quote! { Some(#g) },
            None => quote! { None },
        };

        rule_entries.push(quote! {
            RuleInfo {
                name: #name,
                from_states: &[#(#from_states),*],
                to_state: #to_state,
                op_name: #op_name,
                guard: #guard_token,
            }
        });
    }

    tokens.extend(quote! {
        pub const RULES: &[RuleInfo] = &[
            #(#rule_entries),*
        ];

        pub fn rules_for_op(op_name: &str) -> Vec<&'static RuleInfo> {
            RULES.iter().filter(|r| r.op_name == op_name).collect()
        }

        pub fn rules_from_state(state: &str) -> Vec<&'static RuleInfo> {
            RULES.iter().filter(|r| r.from_states.contains(&state)).collect()
        }
    });

    tokens
}

fn generate_footprints(ir: &TtdIR) -> TokenStream {
    if ir.footprints.is_empty() {
        return quote! {};
    }

    let mut tokens = quote! {
        // ─── Footprints ──────────────────────────────────────────────────────────

        /// Footprint metadata (read/write sets).
        #[derive(Debug, Clone)]
        pub struct FootprintInfo {
            pub op_name: &'static str,
            pub reads: &'static [&'static str],
            pub writes: &'static [&'static str],
            pub creates: &'static [&'static str],
            pub deletes: &'static [&'static str],
        }
    };

    let mut footprint_entries = Vec::new();

    for fp in &ir.footprints {
        let op_name = &fp.op_name;
        let reads: Vec<_> = fp.reads.iter().map(|s| s.as_str()).collect();
        let writes: Vec<_> = fp.writes.iter().map(|s| s.as_str()).collect();
        let creates: Vec<_> = fp.creates.iter().map(|s| s.as_str()).collect();
        let deletes: Vec<_> = fp.deletes.iter().map(|s| s.as_str()).collect();

        footprint_entries.push(quote! {
            FootprintInfo {
                op_name: #op_name,
                reads: &[#(#reads),*],
                writes: &[#(#writes),*],
                creates: &[#(#creates),*],
                deletes: &[#(#deletes),*],
            }
        });
    }

    tokens.extend(quote! {
        pub const FOOTPRINTS: &[FootprintInfo] = &[
            #(#footprint_entries),*
        ];

        pub fn footprint_for_op(op_name: &str) -> Option<&'static FootprintInfo> {
            FOOTPRINTS.iter().find(|f| f.op_name == op_name)
        }
    });

    tokens
}

fn generate_registry(ir: &TtdIR) -> TokenStream {
    if ir.registry.is_empty() {
        return quote! {};
    }

    let mut tokens = quote! {
        // ─── Registry ────────────────────────────────────────────────────────────

        /// Registry entry (type ID mapping).
        #[derive(Debug, Clone)]
        pub struct RegistryEntryInfo {
            pub type_name: &'static str,
            pub id: u32,
            pub deprecated: bool,
        }
    };

    let mut registry_entries = Vec::new();

    for entry in &ir.registry {
        let type_name = &entry.type_name;
        let id = entry.id;
        let deprecated = entry.deprecated;

        registry_entries.push(quote! {
            RegistryEntryInfo {
                type_name: #type_name,
                id: #id,
                deprecated: #deprecated,
            }
        });
    }

    tokens.extend(quote! {
        pub const REGISTRY: &[RegistryEntryInfo] = &[
            #(#registry_entries),*
        ];

        pub fn registry_id_for_type(type_name: &str) -> Option<u32> {
            REGISTRY.iter().find(|e| e.type_name == type_name).map(|e| e.id)
        }

        pub fn registry_type_for_id(id: u32) -> Option<&'static str> {
            REGISTRY.iter().find(|e| e.id == id).map(|e| e.type_name)
        }
    });

    tokens
}

fn generate_invariants(ir: &TtdIR) -> TokenStream {
    if ir.invariants.is_empty() {
        return quote! {};
    }

    let mut tokens = quote! {
        // ─── Invariants ──────────────────────────────────────────────────────────

        /// Invariant metadata (law compiler stubs for v2).
        #[derive(Debug, Clone)]
        pub struct InvariantInfo {
            pub name: &'static str,
            pub expr: &'static str,
            pub severity: &'static str,
        }
    };

    let mut invariant_entries = Vec::new();

    for inv in &ir.invariants {
        let name = &inv.name;
        let expr = &inv.expr;
        let severity = inv.severity.as_deref().unwrap_or("error");

        invariant_entries.push(quote! {
            InvariantInfo {
                name: #name,
                expr: #expr,
                severity: #severity,
            }
        });
    }

    tokens.extend(quote! {
        pub const INVARIANTS: &[InvariantInfo] = &[
            #(#invariant_entries),*
        ];

        pub fn invariant_by_name(name: &str) -> Option<&'static InvariantInfo> {
            INVARIANTS.iter().find(|i| i.name == name)
        }
    });

    tokens
}

fn generate_emissions(ir: &TtdIR) -> TokenStream {
    if ir.emissions.is_empty() {
        return quote! {};
    }

    let mut tokens = quote! {
        // ─── Emissions ───────────────────────────────────────────────────────────

        /// Emission declaration metadata.
        #[derive(Debug, Clone)]
        pub struct EmissionInfo {
            pub channel: &'static str,
            pub event: Option<&'static str>,
            pub op_name: &'static str,
            pub condition: Option<&'static str>,
            pub within_ms: Option<u64>,
        }
    };

    let mut emission_entries = Vec::new();

    for em in &ir.emissions {
        let channel = &em.channel;
        let event = em.event.as_deref();
        let op_name = &em.op_name;
        let condition = em.condition.as_deref();
        let within_ms = em.within_ms;

        let event_token = match event {
            Some(e) => quote! { Some(#e) },
            None => quote! { None },
        };
        let condition_token = match condition {
            Some(c) => quote! { Some(#c) },
            None => quote! { None },
        };
        let within_token = match within_ms {
            Some(w) => quote! { Some(#w) },
            None => quote! { None },
        };

        emission_entries.push(quote! {
            EmissionInfo {
                channel: #channel,
                event: #event_token,
                op_name: #op_name,
                condition: #condition_token,
                within_ms: #within_token,
            }
        });
    }

    tokens.extend(quote! {
        pub const EMISSIONS: &[EmissionInfo] = &[
            #(#emission_entries),*
        ];

        pub fn emissions_for_op(op_name: &str) -> Vec<&'static EmissionInfo> {
            EMISSIONS.iter().filter(|e| e.op_name == op_name).collect()
        }

        pub fn emissions_for_channel(channel: &str) -> Vec<&'static EmissionInfo> {
            EMISSIONS.iter().filter(|e| e.channel == channel).collect()
        }
    });

    tokens
}

/// Map a GraphQL base type name to a Rust type.
fn map_type(gql_type: &str) -> TokenStream {
    match gql_type {
        "Boolean" => quote! { bool },
        "String" => quote! { String },
        "Int" => quote! { i32 },
        "Float" => quote! { f32 },
        "ID" => quote! { String },
        // Custom scalars - map to appropriate Rust types
        "Hash" => quote! { String },      // 64-char hex string (SHA-256)
        "Timestamp" => quote! { String }, // ISO 8601 timestamp string
        "JSON" => quote! { serde_json::Value },
        other => {
            let ident = safe_ident(other);
            quote! { #ident }
        }
    }
}
